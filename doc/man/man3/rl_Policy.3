.TH "rl::Policy< State, Action >" 3 "Wed Oct 28 2015" "LearningAlgorithms" \" -*- nroff -*-
.ad l
.nh
.SH NAME
rl::Policy< State, Action > \- 
.SH SYNOPSIS
.br
.PP
.PP
\fC#include <Policy\&.h>\fP
.PP
Inherited by \fBrl::LookupPolicy< State, Action >\fP\&.
.SS "Public Types"

.in +1c
.ti -1c
.RI "typedef State \fBStateT\fP"
.br
.ti -1c
.RI "typedef Action \fBActionT\fP"
.br
.ti -1c
.RI "typedef \fBPolicy\fP< \fBStateT\fP, \fBActionT\fP > \fBPolicyT\fP"
.br
.ti -1c
.RI "typedef std::shared_ptr< \fBPolicyT\fP > \fBPolicyPtrT\fP"
.br
.ti -1c
.RI "typedef std::shared_ptr< const \fBPolicyT\fP > \fBPolicyConstPtrT\fP"
.br
.in -1c
.SS "Public Member Functions"

.in +1c
.ti -1c
.RI "\fBPolicy\fP ()"
.br
.ti -1c
.RI "\fBPolicy\fP (const \fBPolicy\fP &p)"
.br
.ti -1c
.RI "virtual \fB~Policy\fP ()"
.br
.ti -1c
.RI "virtual bool \fBgetAction\fP (const State &s, Action &targetAction) const =0"
.br
.ti -1c
.RI "virtual void \fBbestAction\fP (const State &s, const Action &a, float utility=1\&.0, float confidence=1\&.0)=0"
.br
.ti -1c
.RI "virtual \fBPolicyPtrT\fP \fBclone\fP () const =0"
.br
.ti -1c
.RI "virtual void \fBprint\fP (std::ostream &o) const =0"
.br
.in -1c
.SS "Friends"

.in +1c
.ti -1c
.RI "std::ostream & \fBoperator<<\fP (std::ostream &o, const \fBPolicyT\fP &p)"
.br
.in -1c
.SH "Detailed Description"
.PP 

.SS "template<class State, class Action>class rl::Policy< State, Action >"
Implements a policy: Which Action to perform in which State\&. This can be implemented by looking up a State in a table, or by a learning function which generates Actions out of States\&.
.PP
\fBParameters:\fP
.RS 4
\fIState\fP template class for State description\&. Prerequisite: Must support < operator, an be uniquely identifiable, i\&.e\&. suitable to use in a std::map as key\&. Even if the \fBReward\fP is being calculated as a function by the underlying implementation, it is to be made sure that a map-lookup can be used as well for each state\&. 
.br
\fIAction\fP represents an action to be performed in a state\&. Can be any datatype, but it should provide the assignment operator and a copy constructor (if it is a class)\&. It is not intended to use complex Action datatypes here (if you have complex ones, use an index to the complex action instead), as the datatype is internally copied\&. 
.RE
.PP
\fBAuthor:\fP
.RS 4
Jennifer Buehler 
.RE
.PP
\fBDate:\fP
.RS 4
May 2011 
.RE
.PP

.SH "Member Typedef Documentation"
.PP 
.SS "template<class State , class Action > typedef Action \fBrl::Policy\fP< State, Action >::\fBActionT\fP"

.SS "template<class State , class Action > typedef std::shared_ptr<const \fBPolicyT\fP> \fBrl::Policy\fP< State, Action >::\fBPolicyConstPtrT\fP"

.SS "template<class State , class Action > typedef std::shared_ptr<\fBPolicyT\fP> \fBrl::Policy\fP< State, Action >::\fBPolicyPtrT\fP"

.SS "template<class State , class Action > typedef \fBPolicy\fP<\fBStateT\fP,\fBActionT\fP> \fBrl::Policy\fP< State, Action >::\fBPolicyT\fP"

.SS "template<class State , class Action > typedef State \fBrl::Policy\fP< State, Action >::\fBStateT\fP"

.SH "Constructor & Destructor Documentation"
.PP 
.SS "template<class State , class Action > \fBrl::Policy\fP< State, Action >::\fBPolicy\fP ()\fC [inline]\fP"

.SS "template<class State , class Action > \fBrl::Policy\fP< State, Action >::\fBPolicy\fP (const \fBPolicy\fP< State, Action > & p)\fC [inline]\fP"

.SS "template<class State , class Action > virtual \fBrl::Policy\fP< State, Action >::~\fBPolicy\fP ()\fC [inline]\fP, \fC [virtual]\fP"

.SH "Member Function Documentation"
.PP 
.SS "template<class State , class Action > virtual void \fBrl::Policy\fP< State, Action >::bestAction (const State & s, const Action & a, float utility = \fC1\&.0\fP, float confidence = \fC1\&.0\fP)\fC [pure virtual]\fP"
Under certain circumstances, the Action a was determined best for the State s\&. This should lead to an update of the policy, either by inserting/replacing this action in a table, or by feeding a learning algorithm\&. If available, a utility estimate for this state-action pair can be passed for use by learning algorithms, along with a confidence value [0\&.\&.1] that this action will successfully lead to this utility\&. This could be used to trade off the choice of an action using a risk factor, when returning an action in getAction(State&)\&. In a simple state-action lookup implementation, the parameters confidence and utility won't have any effect\&. 
.PP
Implemented in \fBrl::LookupPolicy< State, Action >\fP\&.
.SS "template<class State , class Action > virtual \fBPolicyPtrT\fP \fBrl::Policy\fP< State, Action >::clone () const\fC [pure virtual]\fP"

.PP
Implemented in \fBrl::LookupPolicy< State, Action >\fP\&.
.SS "template<class State , class Action > virtual bool \fBrl::Policy\fP< State, Action >::getAction (const State & s, Action & targetAction) const\fC [pure virtual]\fP"
Get the action to perform in a certain state\&. If non action assigned to this state, returns false\&. Otherwise, will contain the action to be performed in targetAction\&. 
.PP
Implemented in \fBrl::LookupPolicy< State, Action >\fP\&.
.SS "template<class State , class Action > virtual void \fBrl::Policy\fP< State, Action >::print (std::ostream & o) const\fC [pure virtual]\fP"

.PP
Implemented in \fBrl::LookupPolicy< State, Action >\fP\&.
.SH "Friends And Related Function Documentation"
.PP 
.SS "template<class State , class Action > std::ostream& operator<< (std::ostream & o, const \fBPolicyT\fP & p)\fC [friend]\fP"


.SH "Author"
.PP 
Generated automatically by Doxygen for LearningAlgorithms from the source code\&.
